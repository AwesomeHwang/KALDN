# KALDN

### The code will be released soon.

## Performance
  - The benchmark results of our models can be downloaded from [KALDN-tiny](https://gisto365-my.sharepoint.com/:u:/g/personal/sm_hwang_gm_gist_ac_kr/EXUTwHYN5EtKjaXffUvNxqcBPisC8NchZemFq7BaK2Nuag?e=rm7j32) and [KALDN](https://gisto365-my.sharepoint.com/:f:/g/personal/sm_hwang_gm_gist_ac_kr/Ehb9SNtiVf9PhsKJ6Gvtv0QBigO3qa8JhWhvfFYLvyXH-A?e=OWJbob).
  - Performance in PSNR/SSIM on Set5, Set14, BSD100, Urban100 and DIV2K.
  
| Dataset        | KALDN-tiny   | KALDN |
| ------------- |:------------:|:-----:|
| Set5      | 31.86/0.8904     | 31.91/0.8913 |
| Set14     | 28.39/0.7766     | 28.43/0.7778 |
| BSD100    | 27.44/0.7315     | 27.47/0.7322 |
| Urban100  | 25.64/0.7713     | 25.70/0.7733 |
| DIV2K     | 30.21/0.8324     | 30.25/0.8334 |

## Citation
If you find this work useful in your research, please consider citing:
```bibtex
@article{hwang2023making,
  title={Making depthwise convolution SR-friendly via kernel attention injection},
  author={Hwang, Seongmin and Han, Daeyoung and Jeon, Moongu},
  journal={Journal of Visual Communication and Image Representation},
  volume={96},
  pages={103930},
  year={2023},
  publisher={Elsevier},
  doi={https://doi.org/10.1016/j.jvcir.2023.103930}
}
```

## Acknowledgement
